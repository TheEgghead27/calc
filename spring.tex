\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
%%\usepackage[letterpaper, margin=1in]{geometry}
\usepackage{pgfplots}
\usepackage{soul}
\usepackage{graphicx} % Required for inserting images
\usepackage{hyperref}
\usepgfplotslibrary{external}
\tikzexternalize
\pgfplotsset{compat=1.18}
\hypersetup{
    colorlinks,
    linkcolor = black,
    urlcolor = cyan
}

\title{Honner's Honors Calculus (Spring Semester)}
\author{David Chen}
\date{February - June 2024}

\begin{document}

\maketitle

\section{Indeterminate Forms}
Limits of the form $\frac{0}{0}$ or $\frac{\infty}{\infty}$. These do not indicate the true value of the limit.

As a reminder:
$$\lim_{x \to 0^+} \frac{1}{x} = + \infty$$
is a valid limit, but it is invalid to write $$\lim_{x \to 0} \frac{1}{x}$$

\subsection{L'Hôpital's Rule}
Suppose $f(x)$ and $g(x)$ are differentiable and that $g'(x) \ne 0$ around a. If $\lim_{x\to a} \frac{f(x)}{g(x)}$ produces the indeterminate form $\frac{0}{0}$ or $\frac{\pm \infty}{\pm \infty}$, then $$\lim_{x \to a} \frac{f(x)}{g(x)} = \lim_{x \to \infty} \frac{f'(x)}{g'(x)}$$ provided that the limit on the right exists or is equal to $\pm \infty$.

For L'Hôpital's Rule to apply, we must have a \emph{ratio} of functions, and in a true indeterminate form.

\subsubsection{Pseudo-proof}
Suppose $f$, $g$ are differentiable, and $\lim_{x \to a} f(x) = lim_{x \to a} g(x) = 0$. Recall, by linearization, we approximate $f$ around $a$ as $f(x) \approx f(a) + (x-a)f'(a)$. Consider that                                                                                              

\begin{align*}
   \frac{f(x)}{g(x)} & \approx \frac{f(a) + (x-a)f'(a)}{g(a) + (x-a)g'(a)} \\
                     & \approx \frac{0 + (x-a)f'(a)}{0 + (x-a)g'(a)} \\
                     &       = \frac{f'(a)}{g'(a)}
\end{align*}

\subsection{Improper Integrals}
An improper integral is an integral with an infinite limit of integration, or there exists a finite number of discontinuities between the limits of integration.

Note that this integral may not exist, in which case it diverges (usually to $\pm \infty$). If the limit exists, then the integral converges.

Example/Definition:
$$\int_{1}^{\infty} e^{-x} dx = \lim_{b \to \infty} \int_{1}^{b} e^{-x} dx $$

We must also use an improper integral bound limit to account for discontinuities:
$$\int_{-1}^{1} \frac{1}{x^2} = \lim_{b \to 0} \int_{-1}^{b} \frac{1}{x^2} + \lim_{d \to 0} \int_{d}^{1} \frac{1}{x^2} $$

\subsubsection{Some Ideas to be Wary Of}
These are reasonable statements about improper integrals with a bound of $\infty$, but they are not accurate.

\begin{enumerate}
    \item The area accumulates forever, thus it is infinite.
    \item The region is unbounded, thus its area is infinite.
    \item \st{Just because the rate of accumulation (accumulated area) decreases, that does not guarantee that the total area is finite.} Beware $\frac{1}{x}$.
\end{enumerate}

\subsubsection{Bounding Argument to Provide Convergence/Divergence}
If $0 \le f(x) \le g(x)$ then $$\int_{1}^{\infty} f(x) dx \le \int_{1}^{\infty} g(x) dx$$.

Suppose you want to show that $f(x)$ converges. If you can find a $f(x) \ge f(x)$ that converges, then $f(x)$ converges. (A similar argument can be used to prove $g(x)$ diverges.)

\section{Area/Volume (BC)}
\subsection{Area Between Two Curves}
If $f$ and $g$ are continuous on $[a,b]$ with $f(x) \ge g(x)$ for $x \in [a,b]$, then the area between $f$ and $g$ from $a$ to $b$ is $$\int_{a}^{b} (f-g)dx$$ (or $\int_{a}^{b} |f-g| dx$).

This can also be interpreted geometrically as the integral of the vertical difference between $f$ and $g$.

Generally, the area of such a region is all positive, unlike the area ``under'' a curve.

\subsection{Solids of Revolution}
Solids with axial symmetry about an axis of revolution.

\begin{enumerate}
    \item Sketch the solid formed by revolving a region $R$ about an axis.
    \item Suggest a method for computing the volume of the solid.
\end{enumerate}

Do be mindful of the fact that $V \propto Ar$, the radius (distance from axis of rotation) matters.

\subsubsection{Disk/Washer Method}
Integrates parallel to the axis of rotation. May be inconvenient, if not impossible, when finding an inverse function for $x$ in terms of $y$ is necessary.

Based on a Riemann Sum of small disks $\pi r^2h$ becoming $$\lim_{n \to \infty} \sum_{i=1}^{n} \pi(f(x_i)^2)\Delta x_i$$

Washers are merely the difference in area between a large disk and a concentric small disk.

Let $f(x)$ be the function producing the curve underneath which the region $R$ is bounded by (with the other bounding sides being $x = a$, $x = b$, and $g(x)$). Additionally, let $g(x)$ be the bottom bound curve function. It is possible that $g(x) = 0$ (bottom bound is simply the x-axis). In this case, we are revolving about the x-axis.

$$V = \pi \int_{a}^{b} (f(x)^2) dx$$
$$V = \pi \int_{a}^{b} (f(x)^2 - g(x)^2) dx$$

\subsubsection{Shell Method}
Integrates perpendicular to the axis of rotation. May be inconvenient if one lacks a curve function corresponding to these axes.

Based on a Riemann Sum of rectangular prisms $2 \pi rhw$ becoming
$$\lim_{n \to \infty} \sum_{i=1}^{n} 2 \pi \cdot r(x_i) \cdot f(x_i) \Delta x_i$$

Shells can be "unwrapped" into a figure resembling a rectangular prism, with the difference in area approaching $0$ as $w = \Delta x \to 0$.

Let $f(x)$ be the function producing the curve underneath which the region $R$ is bounded by (with the other bounding sides being $x = a$, $x = b$, and $y = 0$). Let $r(x)$ be the function representing the distance ("radius") of the curve from the axis of rotation (usually $r(x) = b - x$, with $b$ potentially being $0$). In this case, we are revolving about the y-axis.

$$V = 2\pi \int_{a}^{b} r(x) \cdot f(x) dx$$

\subsubsection{Volume by Known Cross Section}
Let $A(x)$ be the area of the cross section.

$$V = \int_{a}^{b} A(x)dx$$

The Disk/Washer method is a special case of the volume by known cross section ($A(x) = 2\pi x^2$, circles).

\subsection{Arclength}
The length of an arc. Defined as
$$ s = \int_{a}^{b} \sqrt{1+(f'(x))^2} dx$$

Based on using infinitely many line segments to approximate the length of an arc.
$S = \sqrt{(x_1-x_0)^2} + \sqrt{(x_2-x_1)^2} + ... + \sqrt{(x_n-x_{n-1})^2}$ ($\sum_{i=1}^n \sqrt{(\Delta x_n)^2 + (\Delta y_n)^2}$)

For each term $\Delta s$, $\Delta s^2 = (\Delta x)^2 + (\Delta y)^2$.
Since  $\Delta y = f(x + \Delta x) - f(x) = \frac{f(x + \Delta x) - f(x)}{\Delta x}\Delta x$, $\Delta y = f'(x)\Delta x$.

\begin{align*}
    S & = \sum_{i=1}^n \sqrt{(\Delta x_n)^2 + (f'(x_n)\Delta x_n)^2} \\
      & = \sum_{i=1}^n \sqrt{(\Delta x_n)^2(1 + f'(x_n)^2)} \\
      & = \int \sqrt{dx^2(1 + f'(x)^2)} \\
      & = \int \sqrt{1 + (f'(x))^2} dx
\end{align*}

\subsubsection{The Three Forms of Arclength You can Do}
\begin{enumerate}
    \item Lines
    \item Convenient u-sub polynomial
    \item Circles (requires arcsine)
    \item Calculator and cope
\end{enumerate}

\subsection{Surface Areas of Revolution}
Integrates using lateral surface areas of frustrums (difference between two right circular cones).

Letting $r_1$, $l_1$ be the radius and slant height of the smaller cone, $r_2$, $l_1 + l$ be the radius and slant height of the second cone:
$$A = \pi r_2(l_1 + l) - \pi r_1 l_1 = \pi[(r_2 - r_1)l_1 + r_2l]$$

Based on similar triangles,
$$\frac{l_1}{r_1} = \frac{l_1 + 1}{r_2}$$

so $r_2 l_1 = r_1 l_1 + r_1 l$, $r_1 l = (r_2 - r_1)l_1$, and letting $r = \frac{r_1 + r_2}{2}$

$$A = \pi (r_2 + r_1)l = 2 \pi r l$$

When we are integrating, $l$ is the arclength, and $r$ is the radius from the axis of rotation, likely $f(x) = y$ or $g(y) = x$.

Thus, for rotation about the x-axis:
$$S = \int_{a}^{b} 2 \pi f(x) \sqrt{1 + f'(x)^2} dx = \int_{a}^{b} 2 \pi y \sqrt{1 + g'(y)^2} dy$$

and for rotation about the y-axis:
$$S = \int_{a}^{b} 2 \pi x \sqrt{1 + f'(x)^2} dx = \int_{a}^{b} 2 \pi g(y) \sqrt{1 + g'(y)^2} dy$$


\section{Conic Sections}
Conic sections are obtained through slicing a cone. The different types of conic section have analogous properties.

\subsection{Parabola}

\subsubsection{Construction/Locus}
A parabola is the locus (of points in the plane) that is equidistant from a given point (focus) and a given line (directrix).
\begin{flushright}
    - The locus (set of points) definition of a parabola.
\end{flushright}

\subsubsection{Focus/Directrix}
For a parabola of focus point $F(a,b)$, directrix $y=k$:
$$\sqrt{(x-a)^2 + (y-b)^2} = |y-k|$$

\subsubsection{Analytic Properties}
\begin{itemize}
    \item $p$ is the focal length, the distance between the vertex of a parabola and its focus/directrix.
    \item The distance between focus and directrix is $2p$.
    \item In the special case that the focus is on the y-axis ($F(0, p)$), the directrix is $y = -p$, the equation of the parabola has the form $$x^2 = 4py$$ or $$y^2=4px$$
    
    One can use translations (as they are rigid motions) to orient a parabola into this form. This includes completing the square.

    \item A chord of a parabola is a line segment with two intersections with the parabola.
        \begin{itemize}
            \item The focal chord is a chord that also spans through the focus.
            \item The Latus Rectum is the focal chord parallel to the directrix. The length is the focal width, $w = 4p$.
        \end{itemize}

    \item For a parabola $y=x^2$, a chord of endpoints $(a, a^2)$ and $(b, b^2)$ has a parallel tangent line at $(\frac{a+b}{2}, (\frac{a+b}{2})^2$.
    \item Perpendicular tangent lines on a parabola will intersect on the directrix.
    \item The y-intercept of a line tangent to $y=f(x)$ at $(a, a^2)$ has a y-intercept of $-a^2$.
\end{itemize}

\subsubsection{Reflective Property}
The reflective property of the parabola is that the angle between a ray perpendicular to the directrix, and the tangent line at the intersection, is equal to the angle between the focus and that point of intersection. (All inbound rays will converge at the focus, useful for satellite dishes, all rays emitted from the focus will go in the same direction, useful for lights).

\subsection{Ellipse}
\subsubsection{Construction/Locus}
The locus of points where the sum of the two focal distances is a constant $2a$.

\paragraph{Fundamental Ellipse Equation (Focal Sum/Focal Width)}
$$F_1P + F_2P = 2a$$

\paragraph{Familiar Ellipse Equation}
$$\frac{x^2}{a^2} + \frac{y^2}{b^2} = 1$$
\\
Based on  $b^2x^2+a^2y^2=a^2b^2$ as derived from the Fundamental Ellipse Equation.

Note that $b^2 = a^2 - c^2$, $c^2=a^2-b^2$.

\subsubsection{Focus/Directrix}
The ratio of distance between a point to a focus $(0, c)$ of the ellipse, and the line $x = \frac{a^2}{c} = \frac{a}{e}$ is a constant:
$$\frac{\sqrt{(x-c)^2+y^2}}{|x-\frac{a}{e}|} = \frac{c}{a} = e < 1$$

The parabola is a special case of this equation with $e = 1$.

\subsubsection{Analytic Properties}
Expressions are provided for the special case of ellipses centered at $(0, 0)$ and with the x-axis as the major axis.

\begin{itemize}
    \item Foci: Points $F_1(-c, 0)$ and $F_2(c, 0)$
    \item Focal Radii: $\overline{F_1P}$, $\overline{F_2P}$
    \item Center: $(0, 0)$
    \item Vertices: $(-a, 0)$, $(a, 0)$
    \item Semi-Major Axis Length: $a$ ($a > b$, Major Axis is the wider one)
    \item Semi-Minor Axis Length: $b$
    \item Major Axis Length: $2a$ (see above)
    \item Eccentricity: $e = \frac{c}{a}$, $0 < e < 1$ (The eccentricity of an ellipse is always between $0$ and $1$.)

        As $e \to 0$, the ellipse figure approaches that of a circle.
    \item Area: $ab\pi = (\sqrt{ab})^2\pi$, (related to geometric mean of "principal radii")
    \item Circumference: No closed form exists
\end{itemize}

\subsubsection{Reflective Property}
The reflective property of an ellipse is that the angle between any rays emitted from one focus to the ellipse is equal to the angle between the ray-ellipse intersection and the second focus. (All emitted rays from a focus will dissipate, then reconverge at the second focus at the same time due to the constant focal sum.)

\subsection{Hyperbola}
\subsubsection{Construction/Locus}
The set of all points where the difference of the two focal distances is $2a$.

\paragraph{Fundamental Hyperbola Equation (Focal Difference)}
$$|\sqrt{(x-c)^2+y^2}-\sqrt{(x+c)^2+y^2})| = 2a$$

\paragraph{Familiar Hyperbola Equation}
$$\frac{x^2}{a^2} - \frac{y^2}{b^2} = 1$$

Here, $b^2 = c^2 - a^2$, $c^2 = a^2 + b^2$.

\subsubsection{Focus/Directrix}
The set of points in which the distance to a focus $F(\pm c, 0)$ and a line $x = \frac{a^2}{c} = \frac{a}{e}$ ($a < c$) is a constant ratio $\frac{c}{a} = e > 1$.

This is very similar to the focus/directrix construction of an ellipse, but now the line $x = \frac{a}{e}$ is between the foci.

$$\frac{\sqrt{(x-c)^2+y^2}}{|x-\frac{a}{e}|} = \frac{c}{a} = e > 1$$

\subsubsection{Analytic Properties}
Expressions are provided for the special case of ellipses centered at $(0, 0)$ and with the x-axis as the focal axis.

\begin{itemize}
    \item Foci: Points $F_1(-c, 0)$ and $F_2(c, 0)$
    \item Center: $(0, 0)$
    \item Vertices: $(-a, 0)$, $(a, 0)$
    \item Transverse Axis Length: $2a$
    
    The length of the line segment (distance) between the vertices.
    
    \item Conjugate Axis Length: $2b$
    
    The height of a rectangle bounded by the vertices, with diagonals being the asymptotes; technically this is the line segment centered at the origin, but it is alright to think of it as the side lengths.
    
    \item Eccentricity: $e = \frac{c}{a}$, $e > 1, a < c$
    \item Asymptotes: $y = \pm\frac{b}{a}x$

    Derived from $$\lim_{x \to \infty} \pm \frac{b}{a} \sqrt{x^2-a^2} = y$$ ($x^2 \gg a^2)$
\end{itemize}

\subsubsection{Reflective Property}
The reflective property of a hyperbola is that an exterior ray aimed at a focus $F_1$ will reflect off the portion of the hyperbola near $F_1$ towards the second focus $F_2$.

\subsection{Distance from a Point to a Line}
For a point $P(x_o, y_o)$, and a line given by $Ax + By + C = 0$

$$d = \frac{|C + Ax_o + By_o|}{\sqrt{A^2+B^2}}$$

This is on its own a generalization of the boolean question "is a point on a line?" to a qualitative "how much is this point not on the line?"

This can be generalized to any dimension.

\subsection{Transformations}
In general, transformations are two-variable functions that map planes onto other planes.

\subsubsection{u-v Substitution Method}
\paragraph{Translations}
For a translation $(x, y) \longrightarrow (x + a, y + b)$, one can transform the x-y plane into the u-v plane by letting
\begin{align*}
    u & = x + a  \\
    v & = y + b
\end{align*}

Then, we solve for $x$ and $y$, generating
\begin{align*}
    u - a & = x  \\
    v - b & = y
\end{align*}

So for any point $P(x,y)$, there is a translated point $P'(u-a,v-b)$, or if we relabel the variables to be more familiar, $P'(x-a,y-b)$.

In this case, $du = dx$ and $dv = dy$, representing how this is an isometry with perpendicular axes maintained.

\paragraph{Axial Scaling}
For a translation $(x, y) \longrightarrow (ax, by)$, one can find
\begin{align*}
    \frac{u}{a} & = x  \\
    \frac{v}{b} & = y
\end{align*}

Here, $du = adx$ and $dv = bdy$, this is not an isometry.

If we are to scale a circle in the x-y plane, we get
\begin{align*}
    x^2+y^2 & = 1 \\
    \left( \frac{x}{a} \right)^2 + \left( \frac{y}{b} \right)^2 & = 1
\end{align*}
or an ellipse.

\subsection{Rotations}
For a given point $P(x,y)$, let us find $P' = R_{O, \theta}(x,y)$.

We can rewrite $x$ and $y$ in terms of the trigonometric ratios of the right triangle formed between the point, the x-axis, and the origin.

Letting $r$ be the distance $PO$:
\begin{align*}
    x &= r \cos{\alpha} \\ 
    y &= r \sin{\alpha}
\end{align*}

Because rotation is about a circle centered about a point (in this case, $O(0,0)$), $PO = P'O = r$.
However, the angle has changed from $\alpha$ to $\alpha + \theta$.

Thus, the new coordinates are:
\begin{align*}
    u &= r \cos{\alpha + \theta} = r \cos{\alpha}\cos{\theta} - r \sin{\alpha}\sin{\theta} \\ 
    v &= r \sin{\alpha + \theta} = r \sin{\alpha}\cos{\theta} + r \cos{\alpha}\sin{\theta} \\
    u &= x \cos{\theta} - y \sin{\theta} \\
    v &= x \sin{\theta} + y \cos{\theta}
\end{align*}

If we are rotating a point, we can use these equations directly, with $(u,v)$ being the new image.

However to operate on an equation, we must solve for $x$ and $y$ based on these last two equations.

Making convenient substitutions of $u \cos{\theta}$ and $v \sin{\theta}$, or $u \sin{\theta}$ and $v \cos{\theta}$ will make it possible to resolve the system of equations.\footnote{Alternatively, one can rotate by $-\theta$ to invert the rotation operation.}

In the end, we find that a point $(x,y)$ rotated about the origin by angle $\theta$ has $x$ and $y$ coordinates
\begin{align*}
    x' =  x \cos{\theta} &+ y \sin{\theta} \\
    y' = -x \sin{\theta} &+ y \cos{\theta}
\end{align*}

Or in short, $(x,y) \longrightarrow (x \cos{\theta} + y \sin{\theta}, -x \sin{\theta} + y \cos{\theta})$.

Notice that the new coordinates $(x',y')$ are dependent upon both $x$ and $y$ terms from the original point, indicating an increase in complexity compared to translations and scaling.

\subsection{Unifying Principles}
\begin{itemize}
    \item Reflective Properties
    \item Focus-Directrix Properties
    \item Locus Definitions
    \item Eccentricity - related to the angle of the plane intersecting the cone, indicative of similarity
    \item Symmetry
    \item Conic Section - including degenerate hyperbola (double $abs(x)$) and degenerate ellipse (point) and degenerate parabola (tangent line)
    \item Construction from Dandelin Spheres
    \item Analytic Form
\end{itemize}
\subsubsection{General Analytic Form of Conic Sections}
$$Ax^2 + By^2 + Cxy + Dx + Ey + F = 0$$

Assuming $C = 0$, so there is no cross-term induced rotation:
\begin{itemize}
    \item Circles show up when $A = B$, we simply complete the square and toss the remaining constant terms over to $r^2$.
    \item Ellipses show up when $AC > 0$ (same sign), $A \ne C$.
    \item Hyperbolas show up when $AC < 0$ (different sign).
    \item Parabolas show up with either $A = 0$ \emph{or} $B = 0$.
\end{itemize}

Assuming one of $A, B, C, D, E \ne 0$, it is possible to divide by that number to reveal an equivalent equation with only $5$ variables to solve for. Thus, it is possible to generate a general conic from $5$ points.

Circles can be solved for using $3$ points, and so can (vertical, assuming $B, C = 0$) parabolas.

There are three cases for the \emph{discriminant} of the general conic:
\begin{enumerate}
    \item If $C^2 - 4AB > 0$, the conic section is a hyperbola.
    \item If $C^2 - 4AB = 0$, the conic section is a parabola.
    \item If $C^2 - 4AB < 0$, the conic section is a ellipse.
\end{enumerate}

\section{Parametric}
\subsection{Parameterization}
A parameterization, which produces a parametric curve, defines a set of points $(x, y)$ as functions $(x(t), y(t))$.

A parameterization can be described as a function $r(t) = (x(t), y(t))$, a mapping of the $\mathbb{R}$ number line (the domain) onto a set of points (the range) in $\mathbb{R}^2$. This can also be considered a new coordinate system where the $t$ coordinates correspond to points on a curve rather than an axis.


\paragraph{Parameterization of a line}
Treating points $A$, $B$ as vectors (only addition, subtraction, scalar multiplication):
$$P(t) = (1-t)A + tB$$

If $0 \le t \le 1$, this is a functional definition of line segment AB, and if $t \in \mathbb{R}$, this is a functional definition of line AB.

\paragraph{Eliminating the Parameter}
Although it is possible to eliminate the parameter (solving for $t$ then substituting appropriately, this only produce a super-set ("universe") of the valid points in the parametric curve, for one loses the parameter indicating what points on the curve are valid and "when" (e.g. in particle motion problems).

\paragraph{Graphing a Parametric Curve}
To graph a parametric curve, it is helpful to think of intervals of note in the functions for $x$ and $y$, along with end behavior. Additionally, consider the range/domain of these functions to determine bounds for your parametric curve.

Orientation, in which \emph{direction} the points on the curve "move" as we increase/decrease $t$ (moving along the "number line"), is crucial to understanding a parametric curve. This is why direction must also be indicated in a parametric curve's graph.

\paragraph{Important Observation}
When viewed as a set of points, the graph of a relation has no unique parameterization.

There are infinitely many potential ways to parameterize a curve (as seen below in section \ref{param-examples}), so we may be able to pick and choose a convenient parameterization when needed.

\subsubsection{Common Examples of Parameterization} \label{param-examples}
\paragraph{Parameterization of the Unit Circle}
This is one of the most important parameterizations of a curve.
\[
    \begin{cases}
        x(t) = \cos t \\
        y(t) = \sin t
    \end{cases}
\]

It is possible to show that the set of points is included by the curve $x^2 + y^2 = 1$ by simply squaring, then adding, these expressions for $x$ and $y$.

This is also a restatement of the unit circle definition for $\sin$ and $\cos$ (replace $t$ with $\theta$).

If $x$ and $y$ are swapped, the same curve appears, but the direction becomes clockwise as opposed to counterclockwise, and the points will appear at different $t$ values.

The "speed" of the traversal of the curve can be scaled by putting a factor on t.

\subparagraph{Speed of a Parametric Curve}
For instance, to "double" the "angular velocity (speed) of the point" on circle parameterization:
\[
    \begin{cases}
        x(t) = \cos 2t \\
        y(t) = \sin 2t
    \end{cases}
\]

Refer to later sections to understand what this actually means.

Phase shifts can also be performed in a similar manner by substituting $(t+a)$.

\subparagraph{Scaling a Parametric Curve}
To scale a curve about an axis, simply multiply $x(t)$ or $y(t)$ by a scalar.

For instance, to parameterize an ellipse
$$\frac{x^2}{3^2} + \frac{y^2}{2^2} = 1$$

\[
    \begin{cases}
        x(t) = 3 \cos t \\
        y(t) = 2 \sin t
    \end{cases}
\]

\subparagraph{Translating a Parametric Curve}
To translate a curve $(a,b)$ units from $(0,0)$, simply add $a$ and $b$ to the corresponding functions.

For instance, a unit circle centered at $(a,b)$:

\[
    \begin{cases}
        x(t) = \cos t + a \\
        y(t) = \sin t + b
    \end{cases}
\]

\paragraph{Trivial Parameterization of $y=f(x)$}
For any curve $y = f(x)$:
\[
    \begin{cases}
        x(t) = t \\
        y(t) = f(t)
    \end{cases}
\]

\subsection{Derivatives of Parametric Curves}
Note that "the derivative" is not a meaningful term in this context due to the variety of possible derivatives to take.

\subsubsection{Tangent Lines ("First" and "Second" Derivative of the Curve)}
The slope of the tangent line is $\frac{dy}{dx}$, but we can only immediately derive $\frac{dx}{dt}$ and $\frac{dy}{dt}$.

Good news!
$$\frac{dy}{dx} = \frac{\frac{dy}{dt}}{\frac{dx}{dt}}$$

Usually, if $\frac{dy}{dt} = 0$, the tangent line is horizontal, and if $\frac{dx}{dt} = 0$, the tangent line is vertical. However, if $\frac{dx}{dt} = \frac{dy}{dt} = 0$, there is an indeterminate form that may represent a cusp of the curve (the particle is momentarily "at rest", refer to the velocity section).

\paragraph{Axial Extrema}
Just like in our conception of $y=f(x)$, we can search for extreme y-values by looking for the zeroes of the function for the y-value, $y'(t)$, but we can also find the leftmost/rightmost points by leveraging $x'(t)$.

However, one must also consider end behavior ($t \to \infty)$, for absolute minima/maxima potentially do not exist on an unclosed interval.

\subsubsection{Concavity}
We keep notion of concavity as based on our traditional $y=f(x)$ functions, where the concavity is based on $\frac{d^2y}{dx^2}$.

Bad news! To calculate the second derivative of y with respect to x, you will be calculating
$$\frac{d^2y}{dx^2} = \frac{d}{dx}\left[\frac{dy}{dx}\right] = \frac{\frac{d}{dt}\left[\frac{dy}{dx}\right]}{\frac{dx}{dt}}$$

\subsubsection{Arclength}
\begin{align*}
    S &= \int_{\alpha}^{\beta} \sqrt{\left(\frac{dx}{dt}\right)^2 + \left(\frac{dy}{dt}\right)^2} \,dt \\
    S &= \int_{\alpha}^{\beta} \sqrt{(x'(t))^2 + (y'(t))^2} \,dt
\end{align*}

This is the Riemann sum of the displacement between points on the curve.

Considering that this is a sum of velocity-time products, this arclength integral also represents the distance travelled by the particle from $t=\alpha$ to $t=\beta$.

\subsubsection{Speed}
The speed of a particle at a given moment is
\begin{align*}
    v &= \sqrt{\left(\frac{dx}{dt}\right)^2 + \left(\frac{dy}{dt}\right)^2} \\
    v &= \sqrt{(x'(t))^2 + (y'(t))^2}
\end{align*}
Notice that this is the magnitude (scalar, non-negative value) of the velocity vector (which has direction).

\subsubsection{Velocity}
The velocity vector is $<x'(t), y'(t)>$, and points in the direction of the tangent line when placed upon a point particle on the parametric curve.

For reference, the position vector is $<x(t), y(t)>$.

\subsubsection{Acceleration}
The acceleration vector is
$$<x''(t), y''(t)>$$

\subsubsection{Area "Under" a Parametric Curve}
$$A = \int_{\alpha}^{\beta} y(t) x'(t) \,dt$$

Notice that $x'(t) \,dt$ simply represents the (signed) $\Delta x$, with $x'(t)$ being a local multiplier.

\section{Polar Coordinates}
The polar coordinate system uses coordinates of the form
$$(r, \theta)$$

With $r$ being the \emph{directed} distance from the designated pole point, and $\theta$ being the angle (in standard position) of that point.

The polar coordinate grid is drawn as a series of concentric circles (radius $r$) with straight lines (angle $\theta$) interspersed.

One way to conceptualize this coordinate system is placing a point on "which circle" (distance from pole), then how specifying far to rotate the point about the pole.

The pole is analogous to the origin in the Cartesian plane.

\subsection{Problems with the Polar Coordinate System}
There is no unique representation of points. This is in stark contrast to the Cartesian plane, in which each point has a unique coordinate label.

Coordinates are simply labels for points, and for any point given by the coordinates $(k, \alpha)$, the point can also be specified by any coordinate of the form $$(k, \alpha + (2n)\pi); n \in \mathbb{Z}$$.

Further, the point $(k, \alpha)$ can \emph{also} be specified by coordinates of form $$(-k, (2n+1)\pi); n \in \mathbb{Z}$$

Even worse, the pole point can be represented by \emph{any} coordinates $$(0, \theta); \theta \in \mathbb{R}$$.

\subsection{Transformations in the Polar Plane}
\subsubsection{Reflection over the x-axis}
To reflect a polar graph over the x-axis, substitute $\theta$ for $-\theta$.

If the polar curve remains seemingly unchanged by this transformation, it is symmetric about the x-axis.

\subsubsection{Rotation by an Angle}
To rotate a polar graph by any angle $\phi$, substitute $\theta$ for $\theta - \phi$.

\subsection{Conversions}
The crux of these conversions is \emph{Trigonometry}.

These conversions between coordinate systems can be thought of as functions mapping $\mathbb{R}^2 \mapsto \mathbb{R}^2$.

\subsubsection{Rectangular to Polar}
Remaining aware of domain restrictions on $\arctan$ (in which case the magnitude may need to be negated):

$$(x,y) \mapsto \left( \sqrt{x^2+y^2}, \arctan{\frac{y}{x}}\right)$$

More accurately, $r^2 = x^2 + y^2$.

\subsubsection{Polar to Rectangular}
$$(r, \theta) \mapsto (r \cos{\theta}, r \sin{\theta})$$
Noticing that polar is just a parameterization of $x$ and $y$ in terms of $r$ and $\theta$:
\begin{align*}
    x &= r \cos{\theta} \\
    y &= r \sin{\theta}
\end{align*}

In addition, $\tan{\theta} = \frac{y}{x}$.

\subsection{Common Polar Graphs}
\subsubsection{Circles}

\paragraph{Circles Centered at the Pole}
With $a$ being the radius of the circle (analogous to $x^2+y^2=a^2$):
$$r = a$$

\paragraph{Circles Through the Pole:}
\subparagraph{Diameter on the x-axis}
With $a$ being the \emph{diameter} of the circle (analogous to $\left(x - \frac{a}{2}\right)^2+y^2=\left(\frac{a}{2}\right)^2$):
$$r=a \cos{\theta}$$
\subparagraph{Diameter on the y-axis}
Similarly, a circle with diameter on the y-axis can be put in polar form as:
$$r=a \sin{\theta}$$
\subparagraph{Circle passing an Arbitrary Point}
For a circle that passes through the pole $(0,0$ and $(a,b)$:
$$r = a\sin{\theta} + b\cos{\theta}$$

\subsubsection{Lines}
\paragraph{Lines through the Pole}
$$\theta = \arctan{\frac{y}{x}}$$

\paragraph{Vertical Lines}
With $a$ being the value of the x-intercept (analogous to $x=a$, $a\ne0$):
$$r = a \sec{\theta}$$

\paragraph{Horizontal Lines}
With $a$ being the value of the y-intercept (analogous to $y=a$, $a\ne0$):
$$r = a \csc{\theta}$$

\subsubsection{Parabolas}
With $a$ being the coefficient in $y = \frac{x^2}{a}$
$$r = a\tan{\theta}\sec{\theta}$$

\subsubsection{Limaçon}
Polar curves of the form $r = c \pm \cos{\theta}$ or $r = c \pm \sin{\theta}$, where $c \ne 0$.

For $c > 1$, there is a dimple (slight bend inwards) on the x-axis (for $\cos$) or y-axis (for $\sin$).\\
For $c = 1$, there is a cusp hitting the pole from the x-axis (for $\cos$) or y-axis (for $\sin$). This is also known as a cardioid.\\
For $c < 1$, there is an inner loop.

\subsubsection{Roses}
Polar curves of the form $r=\cos{k\theta}$ (starts at $(0, 1)$) or $r=\sin{k\theta}$ (starts at $(0, 0)$, rotation by $\frac{3\pi}{2}$).\\
When $k$ is even, $2k$ petals appear on the curve, over a period of $2\pi$.\\
When $k$ is odd, $k$ petals appear on the curve, over a period of $\pi$, due to overlaps when $r < 0$ (antiperiodicity).

\subsubsection{Conics}
Conics with one focus at the pole with eccentricity $e$ and directrix at $x = \pm p$, $e,p > 0$ are described by the polar curve

$$r = \frac{ep}{1\pm e\cos{\theta}}$$

Replace $\cos$ with $\sin$ for vertical orientation.

Our notion of eccentricity applies just the same, $e=0$ makes a circle, $e=1$ makes a parabola, $e$ between makes an ellipse, and $e > 1$ makes a hyperbola.
\subsection{Polar and Derivatives}
Once again, "the derivative" is a meaningless term.

\subsubsection{Tangent Lines to Polar Curves} \label{polar-derivatives}
The slope of a tangent line is always $\frac{dy}{dx}$.

Because polar curves are simply a special case of parametric curves:
$$\frac{dy}{dx} = \frac{\frac{dy}{d\theta}}{\frac{dx}{d\theta}}$$

For reference:
\begin{align*}
    \frac{dx}{d\theta} &= \frac{dr}{d\theta}\cos{\theta}-r\sin{\theta}\\
    \frac{dy}{d\theta} &= \frac{dr}{d\theta}\sin{\theta}+r\cos{\theta}
\end{align*}

To find critical values (for \emph{local} minima/maxima), one must solve for zero with these trigonometric expressions.\footnote{Cusps may occur, but the AP exam usually will not try to trick you with such quibbles.}

\subsubsection{Tangents to the Pole}
Tangent lines to the pole are represented by $\theta = s$, where $s$ is a solution for $r = 0$.

The angle at which the curve approaches the pole is also the angle of the tangent line.

\subsubsection{Polar Derivative}
The derivative of $r$ with respect to $\theta$, $\frac{dr}{d\theta}$ is the "polar derivative".

One common question asked on AP exams is what it would mean for $\frac{dr}{d\theta} < 0$, which is that $r \to -\infty$. If $r > 0$, this means that the curve is getting closer to the pole.

\subsection{Polar Area}
Polar Area does NOT work like Cartesian area, as the simplest bounds (given angles $\theta$) do not easily correspond with unit squares.

Based on the area of a circle sector being $\frac{1}{2}r^2\theta$, if we use a Riemann Sum of small sectors to approximate the area of a polar curve, we find that
$$A = \int_{\alpha}^{\beta} \frac{1}{2} \left(f(\theta)\right)^2 d\theta$$

Here,  $r = f(\theta)$, and we assume that $f(\theta)$ is continuous and \emph{non-negative}.

It may also be helpful to leverage the symmetry of certain polar graphs to adjust the bounds such that $f(\theta)$ may remain positive, or to cancel out the coefficient of $\frac{1}{2}$.

\subsubsection{Area Between Polar Curves}
Unlike the area between Cartesian curves, in which we could simply take the vertical difference between the functions, we must graph the functions and split the area into "ice-cream cone" shaped polar area sections that we can integrate.

The boundaries of these sections are at the $\theta$ values where the graphs intersect. Do note that due to pole, $-r$, and $\theta$ cycling shenanigans, it is best to graph the curve first to get an accurate sense of where the intersections are (which may not always be "collisions" where $r$ and $\theta$ are equal). Do \emph{not} forget to check the endpoints!

\subsection{Polar Arclength}
This is an additional section in textbook section 10.4.

\vspace{.15in}
Based on $S = \int_{\alpha}^{\beta} \sqrt{\left(\frac{dx}{dt}\right)^2 + \left(\frac{dy}{dt}\right)^2} \,dt$, with $dt$ replaced with $d\theta$, and using the forms of $\frac{dx}{d\theta}$ and $\frac{dy}{d\theta}$ described in section \ref{polar-derivatives}, cancelling based on the Pythagorean Identity for $\sin$ and $\cos$:

$$L = \int_{\alpha}^{\beta} \sqrt{r^2 + \left(\frac{dr}{d\theta}\right)^2} \,d\theta$$

\section{Sequences and Series}
A sequence of numbers is an ordered list (tuple).\footnote{Sequences may contain different types of elements, but for the purposes of this course, we will only work with sequences of numbers.}

Every sequence is a function $f: \mathbb{N} \to \mathbb{R}$, where $f(n) = a_n$.

Informally, a series is a sum of a sequence.

In this course, we are concerned about infinite series.

\subsection{Basic Sequences}
In general, a sequence of finite length $n$ can be represented in the form
$$a_1, a_2, a_3, \ldots, a_n $$
The $n$th term, $n \in \mathbb{N}$, is represented by $a_n$.\\
A sequence can also be denoted $\left\{ a_n \right\}$ or $\left\{ a_n \right\}_{n = 1}^\infty$.

\subsubsection{Arithmetic Sequences}
An arithmetic sequence (or progression) is a sequence in which $\forall n$, $a_{n+1} - a_n = d$, the difference between any two consecutive terms is a constant, which we call the common difference $d$.

Given $a = a_1$ and $d$, the sequence can be written as
$$a, \left(a + d\right), \left(a + 2d\right), \left(a + 3d\right), \ldots, \left(a + \left(n-1\right)d\right)$$
and any term can be written as
$$a_n = a + (n-1)d$$

This is analogous to a "point-slope" definition of a line, as the arithmetic sequence is in essence a line. One can also define an arithmetic sequence using two "points".

In an arithmetic sequence, every term is the algebraic mean of its (equidistant) neighbors.

\paragraph{Sum of an Arithmetic Series}
The sum of the first $n$ terms in an arithmetic series (sum of the terms of the arithmetic sequence) is
$$S_n = n\frac{a_1+a_n}{2} = \frac{n}{2}\left(2a + \left(n-1\right)d\right)$$
This can be thought of as $n$ times the average.

\subsubsection{Geometric Sequences}
A geometric sequence is a sequence in which $\forall n$, $\frac{a_{n+1}}{a_n} = r$, the ratio between any two consecutive terms is a constant, which we call the common ratio $r$.

Given $a = a_1$ and $r$, any term can be evaluated for as
$$a_n = ar^{n-1}$$

Notice that there is an arithmetic sequence in the exponents of the terms (or the logarithms of the terms).

Interestingly, the geometric sequence also requires two pieces of information, exactly like the arithmetic sequence, to define it (along with the knowledge that it is a sequence of this type).

In a geometric sequence, every term is the geometric mean of its (equidistant) neighbors.

\paragraph{Sum of a Geometric Sequence}
The sum of the first $n$ terms in a geometric series is
$$S_n = \frac{a-ar^n}{1-r}=a\frac{1-r^n}{1-r}$$
This can be thought of as the result of a polynomial long division problem $$\left(1-r^n\right) = \left(1-r\right)\left(r^{n-1} + r^{n-2} + \ldots + r^2 + r + 1\right)$$

Or alternatively, the difference $S_n - rS_n$, where the digits in $rS_n$ (base $r$) are shifted over one digit.

\paragraph{Generic Alternator}
The special case of $r = -1$ is notable because it gives a repeating sequence $\left(1, -1, 1, -1, \ldots\right)$

\subsection{Properties of Sequences}
\subsubsection{Convergence}
A sequence $\left\{ a_n \right\}$ converges if and only if $\lim_{n\to \infty} a_n$ exists. Otherwise, it diverges.

\paragraph{Limit Properties} Assuming that \(\lim_{n \to \infty} a_n = L\) and  \(\lim_{n \to \infty} b_n = K\), in other words, $\left\{ a_n \right\}$ and $\left\{ b_n \right\}$ converge to $L$ and $K$, respectively:
\begin{align*}
    &\lim_{n \to \infty}\left( ca_n \right) = cL  \\
    &\lim_{n \to \infty}\left( a_n \pm b_n \right) = L \pm K  \\
    &\lim_{n \to \infty}\left( a_n b_n \right) = LK  \\
    &\lim_{n \to \infty}\left( \frac{a_n}{b_n} \right) = \frac{L}{K} & \left( b_n \ne 0, K \ne 0 \right)
\end{align*}

\paragraph{Squeeze Theorem for Sequences}
If $$\lim_{n \to \infty} a_n = L = \lim_{n \to \infty} b_n,$$ and $\exists N$ such that, for $n > N$, $$a_n \le c_n \le b_n,$$ then $$\lim_{n \to \infty} c_n = L$$

\paragraph{Absolute Value Theorem for Sequences}
For the sequence $\left\{ a_n \right\}$, if $$\lim_{n \to \infty} |a_n| = 0,$$ then $$\lim_{n \to \infty} a_n = 0$$
This can be considered a special case of the Squeeze Theorem, using $|a_n|$ and $-|a_n|$.

\subsubsection{Monotonicity}
A sequence is monotonic if its terms are non-decreasing or non-increasing.

A monotonically increasing sequence obeys the condition that
$$a_1 \le a_2 \le a_3 \le a_4 \le \ldots \le a_n \le \ldots$$
and a monotonically decreasing sequence obeys the condition that
$$a_1 \ge a_2 \ge a_3 \ge a_4 \ge \ldots \ge a_n \ge \ldots$$

\paragraph{Strict Increasing/Decreasing}
A sequence is strictly increasing if its terms only increase.
$$a_1 < a_2 < a_3 < a_4 < \ldots < a_n < \ldots$$
A sequence is strictly decreasing if its terms only decrease.
$$a_1 > a_2 > a_3 > a_4 > \ldots > a_n > \ldots$$

\subsubsection{Boundedness} \label{monoton}
A sequence $\left\{ a_n \right\}$ is bounded above if there is a real number $M$ such that $a_n \le M$ $\forall n$.

A sequence $\left\{ a_n \right\}$ is bounded below if there is a real number $N$ such that $N \le a_n$ $\forall n$.

A sequence $\left\{ a_n \right\}$ is bounded if it is both bounded above and bounded below.

\paragraph{Important Theorem III}
A sequence of real numbers that is both monotonic and bounded converges.\footnote{Proof is left to the reader who knows real analysis.}

\subsubsection{Miscellaneous}
In addition, sequences can be:
\begin{itemize}
    \item Defined with a piece-wise representation
    \item Change signs irregularly (e.g. $a_n = \sin{n}$)
\end{itemize}

\subsection{Infinite Series}
Every infinite series is really an infinite series of partial sums.

By defining/recasting our question about what it means to add infinitely many terms into a question about convergent series, we are able to apply our existing tools to analyzing infinite series.

"Does this series converge?" is now defined to be the same question as "Does $\left\{ S_n \right\}$ converge?" or "Does $\lim_{n \to \infty} S_n$ exist?"

Unfortunately, even if we can prove that a series converges, we will rarely be able to discern what value it converges to.

\subsubsection{The Fundamental Infinite Series}
The fundamental infinite series is the infinite geometric series
$S_n = a + ar + ar^2 + ar^3 + \ldots + ar^n + \ldots$
which converges to $S = \frac{a}{1-r}$ if $|r| < 1$.

It diverges if $|r| > 1$, and depends if $|r| = 1$ (is $a = 0$?).

We will use the fundamental infinite series as a benchmark for comparing other series.

\paragraph{Source}
We know $S_n = \frac{a\left(1-r^n\right)}{1-r}$.\\
We want to know if $\lim_{n \to \infty} S_n$ exists.\\
Using limit laws for scalar multiples:
$$\lim_{n \to \infty} \frac{a\left(1-r^n\right)}{1-r} = \frac{a}{1-r} \lim_{n\to\infty} \left(1 - r^n\right)$$
We claim that
\begin{enumerate}
    \item If $|r| < 1$, then this limit exists.
    \item If $|r| > 1$, then this limit does not exist.
    \item If $|r| = 1$, it depends on whether or not $a = 0$.
\end{enumerate}

\paragraph{A note on problem solving} When using the value of $r$ to test for convergence, one must first state that a sequence is a geometric series, and then state that because $|r| < 1$ in this case, the sequence converses.

\subsubsection{Harmonic Series}
The infinite series
$$1 + \frac{1}{2} + \frac{1}{3} + \frac{1}{4} + \frac{1}{5} + \ldots + \frac{1}{n} + \ldots$$
or in sigma notation,
$$\sum_{n=1}^{\infty} \frac{1}{n}$$
is called the harmonic series.

\paragraph{Relationship to the n\textsuperscript{th} Term Test} Despite the fact that $\lim_{n \to \infty} \frac{1}{n} = 0$, the sequence diverges, as $S_{2n} - S_n > \frac{1}{2}$.

\subsubsection{Properties of Convergent Infinite Series}
Let $\sum_{n=1}^{\infty} a_n$ and $\sum_{n=1}^{\infty} b_n$ be convergent series.

Then,
\begin{enumerate}
    \item $\sum_{n=1}^{\infty} ca_n$ converges to $c\sum_{n=1}^{\infty} a_n$
    \item $\sum_{n=1}^{\infty} a_n \pm b_n$ converges to $\sum_{n=1}^{\infty} a_n \pm \sum_{n=1}^{\infty} b_n$
\end{enumerate}

In other words, when the sums converge, they have a linear structure in which algebraic properties apply.

\paragraph{Abstract Concept} If the sequence of partial sums is changing at rates decreasing sufficiently quickly, the series will converge.\\
Only the end behavior matters, and we can take off an arbitrary (finite) number of terms off the "front" of the sum with no bearing on convergence/divergence.

\subsection{Convergence/Divergence Tests}
A series either diverges or converges, but some tests only tell if a series converges/diverges in a specific way, and are inconclusive otherwise.

One helpful thing to note is that a value less than a finite number is also finite, and a value greater than $\infty$ is also infinite.

\subsubsection{Geometric Series} The first method to check if a series converges or diverges is to check if the series is geometric in nature.

\subsubsection{\texorpdfstring{The n\textsuperscript{th} Term Test for Divergence}{The Nth Term Test}} If $\lim_{n \to \infty} a_n \ne 0$, then $\sum_{n=1}^{\infty} a_n$ diverges.\\
The test is also referred to as the n\textsuperscript{th} Term Test, or simply the Divergence Test.\\
The test is inconclusive if it does not determine a series to be divergent (it does \emph{not} guarantee the series is not divergent).

Proof is done by taking
\begin{align*}
    &\lim_{n\to \infty} S_n = \lim_{n\to \infty} \left( S_{n-1} + a_{n} \right) \\
    &\lim_{n\to \infty} S_n - \lim_{n\to \infty} S_{n-1} = \lim_{n\to \infty} a_n = 0
\end{align*}

Notice that if $\lim_{n\to \infty} a_n$ does not exist, $\lim_{n\to \infty} S_n$ cannot exist.

\subsubsection{Telescoping Series} One uncommon form of series is one wherein terms of the sequence cancel out, making it easy to write an explicit form of $S_n$. and find the value the series converges to..This may be determined using partial fraction decomposition.

\subsubsection{The Integral Test} If $f(x)$ is \textbf{positive, continuous, and decreasing} for $x\ge1$, and $a_n = f(n)$, then $\sum_{n=1}^{\infty} a_n$ and $\int_{1}^{\infty} f(x) dx$ will either both converge or both diverge.

This test is always conclusive when applicable, but does \emph{not} indicate the value a series may converge to.

Proof is given by showing that the series can be written as a specific Riemann sum with $\Delta x = 1$, either a left-endpoint approximation (greater than the area represented by the integral) or a right-endpoint approximation (starting from $n+1$, less than the area represented by the integral). The fates of the integral and series are tied together.

In short,
$$\sum_{n=1}^{\infty} a_n > \int_{1}^{\infty} f(x)dx > \sum_{n=2}^{\infty} a_n$$

On the AP exam, you are expected to write the improper integral and then, recognizing that an improper integral is a limit, rewrite the improper integral using the limit.

\paragraph{Integral Test Remainder (Non-AP)} If the Integral Test Applies, $S=S_n+R_n$, and $\int_{n+1}^{\infty} f(x)dx \le R_n \le \int_{n}^{\infty} f(x)dx$.

\subsubsection{The P-(Series) Test} An infinite series of the form $\sum_{n=1}^{\infty} \frac{1}{n^p}$, ($p>0$) is a p-series. A p-series converges when $p > 1$, and diverges with $p \le 1$.\\
This is a special case of the Integral Test.

\subsubsection{The (Direct) Comparison Test}
Suppose that $0 < a_n \le b_n$.
\begin{enumerate}
    \item If $\sum_{n=1}^{\infty} a_n$ diverges, then $\sum_{n=1}^{\infty} b_n$ diverges.
    \item If $\sum_{n=1}^{\infty} b_n$ converges, then $\sum_{n=1}^{\infty} a_n$ converges.
\end{enumerate}
We can prove that the sequence of partial sums is monotonically increasing and bounded/unbounded, and apply the Monotonic Sequence Theorem (see \ref{monoton}).

To use a Comparison Test, it is necessary to already take an opinion on whether a series converges or diverges, and make the appropriate comparisons.

\subsubsection{The Limit Comparison Test}
Suppose $a_n > 0$ and $b_n > 0$. If $$\lim_{n\to\infty}\frac{a_n}{b_n} = L$$ where L is finite and positive, then $\sum_{n=1}^{\infty} a_n$ and $\sum_{n=1}^{\infty} b_n$ either both converge or both diverge.

This test is inconclusive when $L = \infty$ or $L = 0$ (which is in essence $\frac{1}{\infty}$).

The test is proven by showing that for $n > N$, $\frac{a_n}{b_n}$ is within $L \pm \epsilon$, so $\left(L - \epsilon\right)b_n < a_n < \left(L + \epsilon\right)b_n$.

\subsubsection{The Alternating Series Test}
Suppose the magnitude $a_n > 0$. The alternating series $$\sum_{n=1}^{\infty} (-1)^{n+1}a_n$$ converges if $\lim_{n \to \infty} a_n = 0$ and $\forall n$, $a_{n+1} \le a_n$ (decreasing).

This can be proved by grouping the terms of the sequence to form a new sequence of partial sums that is monotonically increasing, but bounded by $a_1$ (because the series can also be rewritten as a sequence of monotonically decreasing partial sums).

\paragraph{Alternating Series Remainder} If an alternating series converges to $S$, then a partial sum $S_n$ is always within $a_{n+1}$ of the value. That is, $\forall n$, $|S-S_n| \le a_{n+1}$.

This can be proven by observing that the partial sums always "jump across" the true value $S$, but with decreasing magnitudes.

\subsubsection{Absolute and Conditional Convergence}
A series $\sum_{n}^{\infty}\limits a_n$ is absolutely convergent if $\sum_{n}^{\infty}\limits |a_n|$ converges.\\
A series $\sum_{n}^{\infty}\limits a_n$ is conditionally convergent if $\sum_{n}^{\infty}\limits a_n$ converges, but $\sum_{n}^{\infty}\limits |a_n|$ diverges.\footnote{The "series of the absolute value of $a_n$" $\left(\sum|a_n|\right)$ is NOT the same as the "absolute value of the series" $\left(|\sum a_n|\right)$.}

\paragraph{Theorem} If $\sum_{n}^{\infty}\limits |a_n|$ converges, then $\sum_{n}^{\infty}\limits a_n$ converges.

Consider that $$\sum_{n}^{\infty}a_n + |a_n| \le 2\sum_{n}^{\infty}|a_n|$$
so by Direct Comparison, $\sum_{n}^{\infty}\limits a_n + |a_n|$ converges, and $$\sum_{n}^{\infty} a_n + |a_n| - \sum_{n}^{\infty} |a_n| = \sum_{n}^{\infty} a_n$$.

\subsubsection{The Ratio Test}
Let $\sum_{n=1}^{\infty}\limits a_n$ be a series with non-zero terms. Then
\begin{enumerate}
    \item $\sum_{n=1}^{\infty}\limits a_n$ converges absolutely if $\lim_{n\to\infty}\limits\lvert \frac{a_{n+1}}{a_n} \rvert < 1$.
    \item $\sum_{n=1}^{\infty}\limits a_n$ diverges if $\lim_{n\to\infty}\limits\lvert \frac{a_{n+1}}{a_n} \rvert > 1$.
    \item The test is inconclusive\footnote{Canonical examples are any p-series, for instance $\sum\frac{1}{n}$ and $\sum\frac{1}{n^2}$.} if $\lim_{n\to\infty}\limits\lvert \frac{a_{n+1}}{a_n} \rvert = 1$.
\end{enumerate}
This can be proved by direct comparison to an appropriate geometric series, along with the n\textsuperscript{th} Term Test.

These conditions can also be used to determine the bounds of the domain of some function of $x$ defined by infinite series, such as $$f(x) = \sum_{n=1}^{\infty} \frac{x^n}{n}$$
We can now ask the question ``when does the series converge?'' (for what $x$ values?). This will be useful in section \ref{power-series}.

\subsubsection{The Root Test}
Let $\sum_{n=1}^{\infty}\limits a_n$ be a series.
\begin{enumerate}
    \item $\sum_{n=1}^{\infty}\limits a_n$ converges absolutely if $\lim_{n\to\infty} \sqrt[n]{|a_n|} < 1$.
    \item $\sum_{n=1}^{\infty}\limits a_n$ diverges if $\lim_{n\to\infty} \sqrt[n]{|a_n|} > 1$.
    \item The test is inconclusive\footnote{Ditto.} if $\lim_{n\to\infty} \sqrt[n]{|a_n|} > 1$.
\end{enumerate}
This test is usually used on series with expressions for $a_n$ with exponents of $n$.

\subsection{Power Series}\label{power-series}
Given a variable $x$, an infinite series of the form
\begin{align*}
    &\sum_{n=0}^{\infty}a_nx^n & &\sum_{n=0}^{\infty}a_n\left(x-c\right)^n
\end{align*}
is a power series in $x$ centered at $x=c$ (such as $c=0$).

A general power series need not be geometric.

\subsubsection{Convergence of a Power Series}
For a power series centered at $x=c$, c being the center of the interval of convergence, exactly one of the following statements will be true:
\begin{enumerate}
    \item The series converges only at $x=c$. ($R = 0$)
    \item $\exists R \left(0 < r < \infty\right)$ such that the series converges absolutely for $|x-c|<R$ and diverges for $|x-c| > R$.
    \item The series converges absolutely for all values of $x\in\mathbb{R}$. ($R = \infty$, $I=(-\infty,\infty)$
\end{enumerate}
We can know for sure that the series converges absolutely on a continuous set containing $(c-R, c+R)$ but we must inspect the endpoints in addition for conditional convergence.

\subsubsection{General Approach to Power Series}
\begin{enumerate}
    \item Determine the radius of convergence. (Ratio Test)
    \item Determine the interval of convergence. (Including endpoints)
    \item What does it converge to?
\end{enumerate}
For assessments like the AP FRQ section, sufficient arguments must be made to justify the convergence/divergence of the endpoints.

\subsubsection{The Most Important Power Series}
Notice that we can now represent any power series as a function $f(x)$ on a continuous interval domain.

$$\sum_{n=0}^{\infty} \square^n = 1 + \square + \square^2 + \square^3 + \square^4 + \ldots = \frac{1}{1-\square}$$

Here, the radius $R = 1$: $-1 < \square < 1$.

\subsubsection{Calculus of Power Series}
The integral/derivative of a series can be rewritten (``distributed'') as a term-wise integral/differentiation (for example, see the Interesting Series below).

For a series that you can model with a function $f(x)$, $\int f(x) = C + \sum \left(\int \square^n\right)$. Similarly to Feynman's Trick, one must calculate the value of $C$ by evaluating these two equivalent expressions.

\paragraph{Interesting Series}
\begin{align*}
    f'(x) = \sum_{n=0}^{\infty} x^n &= 1 + x + x^2 + x^3 + \ldots \\
    f(x) = \sum_{n=1}^{\infty} \frac{x^n}{n} &= x + \frac{x^2}{2} + \frac{x^3}{3} + \ldots \\
    \int f(x)dx = \sum_{n=2}^{\infty} \frac{x^n}{n(n-1)} &= \frac{x^2}{2} + \frac{x^3}{3 \cdot 2} + \frac{x^4}{4 \cdot 3} + \ldots
\end{align*}
Here, one can also see differentiation/integration as a "shifting" of terms.

\subsubsection{Shift and Subtract}
The shift and subtract method is (an optional) method for evaluating certain \emph{absolutely convergent} power series.

By multiplying some series $S$ by a factor $a$ such that the denominators of the terms of the sequence underlying $S$ are "shifted" over, one can try to take $aS - S$ to produce a simpler set of terms for the series, such as a geometric series. This is analogous to the finite difference method of approximating a polynomial's derivatives.

For example:
\begin{align*}
    \sum_{n=1}^\infty \frac{n}{2^n} = S = &\frac{1}{2} + \frac{2}{4} + \frac{3}{8} + \frac{4}{16} + \frac{5}{32} + \ldots \\
    2S = 1 + &\frac{2}{2} + \frac{3}{4} + \frac{4}{8} + \frac{5}{16} + \ldots \\
    -\S = -&\frac{1}{2} - \frac{2}{4} - \frac{3}{8} - \frac{4}{16} - \frac{5}{32} - \ldots  \\
    S = 1 + &\frac{1}{2} + \frac{1}{4} + \frac{1}{8} + \frac{1}{16} + \ldots = 2
\end{align*}

\subsection{Taylor Polynomials}
Given a function $f(x)$ with $n$ derivatives, the Taylor Polynomial of $f(x)$ centered at $x=c$ is constructed to satisfy:
\begin{align*}
    P_n(c)&=f(c)\\
    P_n'(c)&=f'(c)\\
    &\;\;\vdots\\
    P_n^{(n)}(c)&=f^{(n)}(c)
\end{align*}
In essence, this is a generalization of the tangent line to higher-degree polynomials.\\
Suppose $f(x)$ has $n$ derivatives at $x=c$. Then
$$P_n(x)=f(c)+f'(c)\left(x-c\right)+\frac{f''(c)}{2!}\left(x-c\right)^2+\frac{f'''(c)}{3!}\left(x-c\right)^3+\ldots+\frac{f^{(n)}(c)}{n!}\left(x-c\right)^n$$
is the $n$\textsuperscript{th} degree Taylor Polynomial of $f(x)$ centered at $x=c$.\\
In the special case of $c=0$, this is also called a Maclaurin Polynomial.

\subsubsection{Taylor's Remainder Theorem}
If $f(x)$ has at least $n+1$ derivatives in an interval $I$ around $x=c$, then for each $x \in I$, there is a $z$ between $x$ and $c$ such that
$$f(x) = f(c) + f'(c)\left(x-c\right) + \frac{f''(c)}{2!}\left(x-c\right)^2 + \ldots + \frac{f^{(n)}(c)}{n!}\left(x-c\right)^n+R_n(x)$$
where the remainder term $$R_n=\frac{f^{(n+1)}(z)}{(n+1)!}\left(x-c\right)^{n+1}$$
or in short, $f(x) = P_n(x) + R_n(x)$, or $f(x) - P_n(x) = R_n(x)$.

Like the MVT, this is merely an existence theorem (we will never know $z$), but we can use this theorem to extrapolate bounds on the value of a function.

\paragraph{Lagrange Error Bound}
$$\left|R_n(x)\right|\le\frac{\left|x-c\right|^{n+1}}{(n+1)!}\cdot\max\left|f^{(n+1)}(z)\right|$$
for all $z$ between $x$ and $c$.

\subsubsection{Taylor Series}
Suppose $f(x)$ has derivatives of all orders ($f\in C^\infty$, the class of infinitely differentiable functions) at $x=c$, then
$$\sum_{n=0}^\infty \frac{f^{(n)}(c)}{n!}\left(x-c\right)^n=f(c)+f'(c)\left(x-c\right)+\frac{f''(c)}{2!}\left(x-c\right)^2+\ldots$$
is the Taylor Series for $f(x)$ at $x=c$. If $x=0$, we also call this a Maclaurin Series.

This is analogous to Fourier Series, where instead of modeling periodic functions with linear combinations of $\sin{x}$ or $\cos{x}$, functions $f\in C^\infty$ are modelled with polynomials as the basis function.

\paragraph{Theorem} If $\lim_{n\to\infty}\limits R_n=0$ for all $x\in I$, then the Taylor Series converges to its function.

\subsubsection{Important Taylor Series}
Based on the Ratio Test, these three Taylor Series have an interval of convergence of $\left(-\infty,\infty\right)$.
\begin{align*}
    e^x&=\sum_{n=0}^{\infty}\limits\frac{x^n}{n!}=1+x+\frac{x^2}{2}+\frac{x^3}{3!}+\frac{x^4}{4!}+\frac{x^5}{5!}+\ldots\\
    \sin{x}&=\sum_{n=0}^\infty(-1)^n\frac{x^{2n+1}}{(2n+1)!}=x-\frac{x^3}{3!}+\frac{x^5}{5!}-\ldots\\
    \cos{x}&=\sum_{n=0}^\infty(-1)^n\frac{x^{2n}}{(2n)!}=1-\frac{x^2}{2!}+\frac{x^4}{4!}+\ldots
\end{align*}
\paragraph{Other Important Taylor Series}
The series for $\ln{x}$ converges from $(0,2]$, and the others converge from $[-1,1]$.
\begin{align*}
    \frac{1}{1-x}&=\sum_{n=0}^\infty x^n=1+x+x^2+x^3+x^4+x^5+x^6+x^7+x^8+\ldots\\
    \ln{x}&=\sum_{n=1}^\infty (-1)^{n-1}\frac{(x-1)^n}{n}=\left(x-1\right)-\frac{\left(x-1\right)^2}{2}+\frac{\left(x-1\right)^3}{3}-\ldots\\
    \arctan{x}&=\sum_{n=0}^\infty (-1)^{n}\frac{x^{2n+1}}{2n+1}=x-\frac{x^3}{3}+\frac{x^5}{5}-\frac{x^7}{7}+\frac{x^9}{9}-\frac{x^{11}}{11}+\ldots
\end{align*}
Note that $\arctan{x}=\int \frac{1}{x^2}dx$. Also, many substitutions $\square$ can be made for $x$ in series such as $e^x$.

\section{Differential Equations}
Equations written in terms of derivatives. Solutions are function(s), not numbers.

The general solution describes a family of functions that could be solutions to a differential equation, while the particular solution is the function that is the solution to a differential equation \emph{and} a given constraint ($y(a)=b$).

\subsection{Separation of Variables}
Also known as the only method required for solving AP-level differential equations.

Multiply and divide the equation such that $\frac{dy}{dx}$ will be separated into two sides with only their respective variables, then integrate. Although both sides technically have a $C$, it is simpler to treat them as a single $C$.

\subsection{Exponential Growth Models}
The fundamental differential equation is $\frac{dy}{dt}=ky$.
Assuming $y>0$, $\ln{|y|}=\ln{y}=kt+C$
$$y=e^{kt+C}=e^ce^{kt}=Ce^{kt}$$

\subsubsection{Logistic Growth (BC)}
This is a second order approximation of population growth.
$$\frac{dy}{dt}=ky\left(1-\frac{y}{L}\right)$$

There are two parameters, $k$ to control the speed at which growth/decay occurs, and $L$, the limiting value of the function as $t\to\infty$.

$\frac{dy}{dx}$ is at a maximum exactly between the limits of the logistic growth curve. (the graph of $\frac{dy}{dt}$ as a function of $y$ is a parabola with vertex $\frac{L}{2}$, roots $0$ and $L$).

The closed form solution, derived through partial fraction decomposition, is $y=\frac{L}{1+be^{-kt}}$, but this is not required for the AP exam.

\subsection{Slope Fields}
A slope field is a lattice of small tangent lines representing $\frac{dy}{dx}$ at a given point in the field.\footnote{This is not to be confused with a vector field.}

It is useful to use slope fields to develop an educated guess for particular solutions to non-separable differential equations.

\subsubsection{Euler's Method}
A method of successive approximation for points on a solution curve.

Instead of using a single tangent line to approximate the value of $y(c+a)$ given an initial constraint value of $y(c)$, which we denote $(x_0,y_0)=(c,y(c))$, and the slope field $F(x,y)$, we subdivide the interval into subintervals of a given "step size" ($h$).  We then compute the endpoints of each interval $(x_n,y_n)$ iteratively using the approximation $$y_n=y_{n-1}+h\cdot F\left(x_{n-1},y_{n-1}\right)$$ until we reach the desired $x_n$.

Note that for nonlinear conditions, evaluations may become chaotic: errors may be amplified or dampened in unpredictable ways due to minor miscalculations/changes in step size.

\section{Extension: Statistics}
For our definitions of statistics, we base all of our analysis on sets.

Statistics in general is about trading accuracy/verbosity in (numerical) data for a simpler/terser amount of description numbers. A "first order approximation" can be done with measures of central tendency, and additional information can be conveyed by variation from that central tendency.

\subsection{Sample Space}
The set ($S$) of all possible outcomes.
\subsubsection{Event} An event $E$ is a subset of $S$.

The probability of an event $E$ is given as $P(E)=Pr(E)=\frac{|E|}{|S|}$ where $|A|$ is the size of the set (cardinality of) $A$.

\paragraph{Complements}
Given $E \subseteq S$, $E^C= S \setminus E = \left\{x \in S | x \notin E\right\}$.

Note that $E \cup E^C = S$, $E \cap E^C = \varnothing$, so
\begin{align*}
    P(S) &= P(E \cup E^C) = P(E) + P(E^C) \\
    1 &= P(E) + P(E^C)
\end{align*}
See section \ref{prob-ax} for more details.

\subsection{Axioms of Probability}\label{prob-ax}
The unifying principles of any probability system.

\begin{enumerate}
    \item $P(E)\ge0$
    \item $P(S)=1$
    \item $P(E \cup F) = P(E) + P(F)$ if $E \cap F = \varnothing$ ($E$ and $F$ are disjoint sets with no overlaps, so their union ("or") will add elements of the set)
\end{enumerate}

\subsubsection{Principle of Inclusion/Exclusion}
Another useful relationship is
$|A \cup B| = |A| + |B| - |A \cap B|$
$$P(A \cup B) = P(A) + P(B) - P(A \cap B)$$

\subsection{Independence}
Two events $A$ and $B$ are independent if $P(A \cap B) = P(A)P(B)$.
Independence is a symmetric relation, is $B$ is independent with respect to $A$, so is $A$ in respect to $B$, as can be verified from \ref{cond-prob}.

\subsubsection{Conditional Probability}\label{cond-prob}
Given two events $A$ and $B$, the conditional probability of $B$ given $A$ denoted $P(B|A)$ is defined to be 
$$P(B|A)=\frac{P(B \cap A)}{P(A)}$$
It is helpful to think of this as a ratio of sets, or a restricted sample space.

Two events $A$ and $B$ are independent if $P(B|A)=P(B)$, as
\begin{align*}
    P(B) &= P(B|A) = \frac{P(B \cap A)}{P(A)}\\
    P(B)P(A) &= P(B \cap A)
\end{align*}

\paragraph{Additional Identities} that follow from the above include
\begin{align*}
    P(A|B)P(B) = P(A \cap B) = P(B|A)P(A)\\
    P(B|A) = P(A|B)\frac{P(B)}{P(A)}\\
    P(A) = P(A|B)P(N)+P(A|B^C)P(B^C)
\end{align*}

\subsection{Binomial Model}
For $n$ independent events, such as a coin flip, the odds of a certain number $k$ of outcomes with probability $p$ occurring is
$$P(x = k) = \binom{n}{k} p^k(1-p)^{n-k}$$
The multiplication/combinatorial terms refer to the commutativity of the events (you can get $3$ heads from $5$ tosses multiple ways).

The sum of $P(x=k)$ for all $k$ is $1$.

\subsection{Random Variables}
A random "variable"\footnote{It is more appropriate to consider these functions.} $X$ represents a set of values in $S$, and maps that set to $\mathbb{R}$.  $X: S \to R$.

The probability of a specific range value being returned from $X$ can be modeled with a (discrete) probability distribution function, which can differ greatly.
For instance, some are skewed, some are symmetric, and some are geometric/exponential.

\subsubsection{Weighted Average} \label{expected}
$$\sum_{s \in S} P(S)X(S)$$ is the weighted average of all values of $x$. This is the most important value associated to a random variable.

\paragraph{Expectation (Expected Value)} Given a random variable $X$, the expectation, or expected value of $X$, is given by
$$E\left[X\right]=\sum_x xP(x)$$ where $x$ ranges over all possible values of $X$.

Expectation is linear. $$E\left[X+Y\right] = E\left[X\right] + E\left[Y\right]$$
Example: expected value of the sum of two six-sided dice $3.5 + 3.5 = 7$.

\subsubsection{Variance} \label{variance}
Variance is a description of variation from the mean $E[X] = \mu$.
$$Var(X) = \sum_x\left(x-\mu\right)^2p(x)$$

A helpful identity is  $$Var[X] = E[X^2] - \left(E[X]\right)^2$$

Notice that we do not use the signed difference from $\mu$, as $\mu$ is constructed to have the property that that sum is $0$.

The standard deviation of a random variable $\sigma(X)$ is defined as
$$\sigma^2(X) = Var(X)$$

\subsection{Continuous Random Variables}
A random variable $X$ is a continuous, random variable if there exists a non-negative function $f(x)$ such that for any set of real number $B$
$$P(X \in B) = \int_B f(x)\,dx$$

$f(x)$ is called the probability density function (PDF).

\subsubsection{Properties}
The basic probability calculation for a continuous random variable $X$ is
$$P(a \le x \le b)=\int_a^b f(x)\,dx$$
the probability that $X$ takes a value between $a$ and $b$.

\begin{itemize}
    \item For $a < b < c$, $P(a \le X \le b) + P(b \le X \le c) = P(a \le X \le c($
    \item $\int_{-\infty}^\infty f(x)\,dx = 1$, as with discrete probability, an event in the sample space \emph{must} occur.
    \item $P(X = a) = 0$, any single value has an infinitesimally minute chance of being chosen.
\end{itemize}

\paragraph{Expected Value} is defined analogously to section \ref{expected}.
$$E[X] = \int_{-\infty}^\infty xf(x)\,dx$$

In addition, for any function $g$ of $X$, $$E[g(X)] = \int_{-\infty}^\infty g(x)f(x)\,dx$$

This is a measure of central tendency.

\paragraph{Variance} is defined analogously to section \ref{variance}.
$$Var(X) = \int_{-\infty}^\infty \left(x-\mu\right)^2f(x)\,dx$$

\paragraph{Mean Absolute Deviation}
$$\int_{-\infty}^\infty |x-\mu|f(x)\,dx$$

\subsubsection{Common PDFs}
The uniform distribution of numbers from $[0, n]$ can be defined as
\[
    f(x) =
    \begin{cases}
        \frac{1}{n} & x \in [0,n] \\
        0 & x \notin [0,n]
    \end{cases}
\]
Notice that we define a PDF to be valued $0$ outside of the relevant interval.

\section{Appendix}
\subsection{Area of an Equilateral Triangle}
Can be derived using the Pythagorean Theorem.
$$A = \frac{\sqrt{3}}{4}s^2$$

\subsection{Surface Area of a Cone}
A (right circular) cone of radius $r$, slant height $l$, can be unwrapped into a sector of radius $l$ with an arc of length $2 \pi r$. Thus, $\theta = \frac{2\pi r}{l}$ ($S = \theta r$).
The area of this sector is
\begin{align*}
    A & = \frac{1}{2} l^2 \theta  \\
      & = \frac{1}{2}l^2\frac{2\pi r}{l}  \\
      & = \pi lr
\end{align*}


Thus, letting $l$ be the lateral length of the cone, $r$ be the radius of the cone's base,
$$SA = \pi rl$$

\subsection{Vector Magnitude}
For a 2-element vector $\Vec{c} = <a,b>$, the magnitude of $\Vec{c}$ is
$$c = \sqrt{a^2 + b^2}$$

This is based on the Pythagorean Theorem/Distance Formula.

\subsection{Polar Integrals}
Below are Wolfram Alpha based calculator tools to aid in verifying select Polar Integrals.

\begin{itemize}
    \item \href{https://www.wolframalpha.com/widgets/view.jsp?id=769788ade06411e063edbd51239787f9}{Polar Area}
    \item \href{https://www.wolframalpha.com/widgets/view.jsp?id=c26cbb9457ff75f58f479364ddb79cd1}{Polar Arclength}
\end{itemize}

\subsection{Rearrangement of Series}
Also known as the Riemann Rearrangement Theorem.

If $\sum_{n=1}^{\infty}\limits a_n$ converges conditionally, you can rearrange the terms in the series to make the series "converge to" any finite number.

This is because we can design two sub-series, $\sum b_n$ ($b_n = a_n > 0$) and $\sum c_n$ ($c_n = a_n < 0$), which are both divergent, and so we can add precisely enough terms from each side so that the series sum will converge to a desired value.

In short, the rules of arithmetic (commutability) do not apply to conditionally convergent series.

\subsection{Formal Power Series}
Combinatorics treats power series as a set of symbols to manipulate.

\subsection{AP Practice}
\subsubsection{MCQ}
All topics will be covered in the MCQ.

\subsubsection{FRQ}
There are 6 FRQs, 30 minutes for 2 calculator-active questions, with an additional 60 minutes for 4 non-calculator questions (though you can go back to the first 2).

Each FRQ is worth 9 points each, 54 points, or $\frac{1}{2}$ of the exam's 108 points are here.

The target is to be over $\frac{2}{3}$ of the points, thus achieving a 5.

There are four types of questions that almost always appear on the AP Calculus BC Exam:
\begin{itemize}
    \item Tabular -- A function is given in the form of a table of values. Often involves approximating slopes with secants, integrals with endpoint sums.
    \item Graphical -- A function (or its derivatives) is given in the form of a graph.
    \item Accumulation -- A function is given as a rule, usually involving an antiderivative/derivative.
    \item Taylor Series
\end{itemize}

Additionally, common topics are
\begin{itemize}
    \item Parametric/Polar
    \item Differential Equations
    \item Area/Volume (by known cross section/washer method, shell method is optional)
    \item Miscellaneous -- As per Campbell's law, the exam seeks to be less predictable due to ``corruption pressures''.
\end{itemize}

\subsubsection{Field Test Questions}
We are paying beta testers, for questions that are meant to be unusual.

\end{document}
